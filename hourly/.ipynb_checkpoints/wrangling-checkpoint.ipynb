{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling - transforming the data into a more suitable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T19:30:02.860685Z",
     "iopub.status.busy": "2021-01-17T19:30:02.860685Z",
     "iopub.status.idle": "2021-01-17T19:30:03.331931Z",
     "shell.execute_reply": "2021-01-17T19:30:03.332930Z"
    }
   },
   "outputs": [],
   "source": [
    "# necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is to load the hourly data that was pulled using the scripts in the data fetching section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T19:30:03.335930Z",
     "iopub.status.busy": "2021-01-17T19:30:03.335930Z",
     "iopub.status.idle": "2021-01-17T19:30:19.822449Z",
     "shell.execute_reply": "2021-01-17T19:30:19.822449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>locationName</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>1512 Malmin raitti 3</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 01:00:00</td>\n",
       "      <td>1512 Malmin raitti 3</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 02:00:00</td>\n",
       "      <td>1512 Malmin raitti 3</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 03:00:00</td>\n",
       "      <td>1512 Malmin raitti 3</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 04:00:00</td>\n",
       "      <td>1512 Malmin raitti 3</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp          locationName  value\n",
       "0 2017-01-01 00:00:00  1512 Malmin raitti 3   0.04\n",
       "1 2017-01-01 01:00:00  1512 Malmin raitti 3   0.04\n",
       "2 2017-01-01 02:00:00  1512 Malmin raitti 3   0.04\n",
       "3 2017-01-01 03:00:00  1512 Malmin raitti 3   0.04\n",
       "4 2017-01-01 04:00:00  1512 Malmin raitti 3   0.04"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = pd.read_csv(\"hourly_dropped.csv\", parse_dates=['timestamp'])\n",
    "ts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we clean the data and restructure it into a more suitable format.\n",
    "\n",
    "* Group the `ts` dataframe by the locations since our data contain electricity demand records from multiple locations.\n",
    "\n",
    "* For each location, we create a dataframe. The index of each of these dataframes are the timestamps of the data (from 2017-January-01 to 2020-January-01). These dataframes are stored in the list `locs`.\n",
    "\n",
    "* For each dataframe, we delete the duplicated records if there are any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T19:30:20.227453Z",
     "iopub.status.busy": "2021-01-17T19:30:19.959449Z",
     "iopub.status.idle": "2021-01-17T19:30:23.539449Z",
     "shell.execute_reply": "2021-01-17T19:30:23.539449Z"
    }
   },
   "outputs": [],
   "source": [
    "groups = ts.groupby('locationName')\n",
    "\n",
    "# divide into different dataframes for each location\n",
    "locs = [groups.get_group(df).set_index('timestamp').value for df in groups.groups]\n",
    "\n",
    "# remove duplicated rows\n",
    "locs = [df[~df.index.duplicated(keep='first')] for df in locs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we further clean the data. As there may be locations whose data are not in hourly resolution, we need to reformat those dataframes so that all of them are in the hourly resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T19:30:23.543449Z",
     "iopub.status.busy": "2021-01-17T19:30:23.542484Z",
     "iopub.status.idle": "2021-01-17T19:30:23.555449Z",
     "shell.execute_reply": "2021-01-17T19:30:23.555449Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a range of timestamps covering the time range of the data.\n",
    "all_dates = pd.date_range(start='2017-01-01', end='2020-01-01', freq='1H')\n",
    "\n",
    "for idx, loc in enumerate(locs):\n",
    "    if len(loc) > len(all_dates): # are there more records (timestamps) than the default dataframe\n",
    "        locs[idx] = locs[idx].resample('1H').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we combine all dataframes in `locs` into 1 big dataframe `df`, in which each column is a location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T19:30:23.560489Z",
     "iopub.status.busy": "2021-01-17T19:30:23.560489Z",
     "iopub.status.idle": "2021-01-17T19:30:25.320449Z",
     "shell.execute_reply": "2021-01-17T19:30:25.320449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>571</th>\n",
       "      <th>572</th>\n",
       "      <th>573</th>\n",
       "      <th>574</th>\n",
       "      <th>575</th>\n",
       "      <th>576</th>\n",
       "      <th>577</th>\n",
       "      <th>578</th>\n",
       "      <th>579</th>\n",
       "      <th>580</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>82.92</td>\n",
       "      <td>36.35</td>\n",
       "      <td>14.25</td>\n",
       "      <td>45.92</td>\n",
       "      <td>34.63</td>\n",
       "      <td>11.47</td>\n",
       "      <td>2.80</td>\n",
       "      <td>43.56</td>\n",
       "      <td>0.04</td>\n",
       "      <td>8.80</td>\n",
       "      <td>...</td>\n",
       "      <td>22.46</td>\n",
       "      <td>49.56</td>\n",
       "      <td>43.48</td>\n",
       "      <td>42.4</td>\n",
       "      <td>21.15</td>\n",
       "      <td>200.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>25.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00</th>\n",
       "      <td>83.91</td>\n",
       "      <td>41.11</td>\n",
       "      <td>13.00</td>\n",
       "      <td>44.80</td>\n",
       "      <td>33.18</td>\n",
       "      <td>11.60</td>\n",
       "      <td>2.76</td>\n",
       "      <td>43.52</td>\n",
       "      <td>0.04</td>\n",
       "      <td>8.56</td>\n",
       "      <td>...</td>\n",
       "      <td>22.32</td>\n",
       "      <td>49.56</td>\n",
       "      <td>43.79</td>\n",
       "      <td>42.4</td>\n",
       "      <td>21.12</td>\n",
       "      <td>100.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>28.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 02:00:00</th>\n",
       "      <td>83.31</td>\n",
       "      <td>40.55</td>\n",
       "      <td>9.45</td>\n",
       "      <td>43.68</td>\n",
       "      <td>32.55</td>\n",
       "      <td>11.46</td>\n",
       "      <td>2.76</td>\n",
       "      <td>43.87</td>\n",
       "      <td>0.04</td>\n",
       "      <td>8.80</td>\n",
       "      <td>...</td>\n",
       "      <td>22.35</td>\n",
       "      <td>50.04</td>\n",
       "      <td>43.67</td>\n",
       "      <td>42.0</td>\n",
       "      <td>21.66</td>\n",
       "      <td>100.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>26.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 03:00:00</th>\n",
       "      <td>84.88</td>\n",
       "      <td>41.33</td>\n",
       "      <td>9.35</td>\n",
       "      <td>45.44</td>\n",
       "      <td>32.54</td>\n",
       "      <td>11.60</td>\n",
       "      <td>2.76</td>\n",
       "      <td>44.10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>8.72</td>\n",
       "      <td>...</td>\n",
       "      <td>22.40</td>\n",
       "      <td>49.32</td>\n",
       "      <td>44.34</td>\n",
       "      <td>41.6</td>\n",
       "      <td>21.25</td>\n",
       "      <td>200.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>26.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 04:00:00</th>\n",
       "      <td>86.23</td>\n",
       "      <td>40.76</td>\n",
       "      <td>9.40</td>\n",
       "      <td>52.64</td>\n",
       "      <td>32.47</td>\n",
       "      <td>11.55</td>\n",
       "      <td>4.12</td>\n",
       "      <td>43.98</td>\n",
       "      <td>0.04</td>\n",
       "      <td>8.72</td>\n",
       "      <td>...</td>\n",
       "      <td>22.40</td>\n",
       "      <td>49.68</td>\n",
       "      <td>43.55</td>\n",
       "      <td>42.0</td>\n",
       "      <td>20.99</td>\n",
       "      <td>200.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>30.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 581 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0      1      2      3      4      5     6      7    \\\n",
       "timestamp                                                                    \n",
       "2017-01-01 00:00:00  82.92  36.35  14.25  45.92  34.63  11.47  2.80  43.56   \n",
       "2017-01-01 01:00:00  83.91  41.11  13.00  44.80  33.18  11.60  2.76  43.52   \n",
       "2017-01-01 02:00:00  83.31  40.55   9.45  43.68  32.55  11.46  2.76  43.87   \n",
       "2017-01-01 03:00:00  84.88  41.33   9.35  45.44  32.54  11.60  2.76  44.10   \n",
       "2017-01-01 04:00:00  86.23  40.76   9.40  52.64  32.47  11.55  4.12  43.98   \n",
       "\n",
       "                      8     9    ...    571    572    573   574    575    576  \\\n",
       "timestamp                        ...                                            \n",
       "2017-01-01 00:00:00  0.04  8.80  ...  22.46  49.56  43.48  42.4  21.15  200.0   \n",
       "2017-01-01 01:00:00  0.04  8.56  ...  22.32  49.56  43.79  42.4  21.12  100.0   \n",
       "2017-01-01 02:00:00  0.04  8.80  ...  22.35  50.04  43.67  42.0  21.66  100.0   \n",
       "2017-01-01 03:00:00  0.04  8.72  ...  22.40  49.32  44.34  41.6  21.25  200.0   \n",
       "2017-01-01 04:00:00  0.04  8.72  ...  22.40  49.68  43.55  42.0  20.99  200.0   \n",
       "\n",
       "                       577    578  579   580  \n",
       "timestamp                                     \n",
       "2017-01-01 00:00:00  108.0  25.91  NaN  69.0  \n",
       "2017-01-01 01:00:00  112.0  28.63  NaN  43.0  \n",
       "2017-01-01 02:00:00  112.0  26.50  NaN  42.0  \n",
       "2017-01-01 03:00:00  112.0  26.89  NaN  42.0  \n",
       "2017-01-01 04:00:00  120.0  30.83  NaN  47.0  \n",
       "\n",
       "[5 rows x 581 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(locs, join='outer', axis=1, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can already spot that there are NaN entries in the dataframe. In other words, for those locations at those timestamps, there was no available data. Although it may be arbitrary, we decided to only take the columns (locations) in which there are less than 100 missing entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T19:30:25.323449Z",
     "iopub.status.busy": "2021-01-17T19:30:25.323449Z",
     "iopub.status.idle": "2021-01-17T19:30:25.414449Z",
     "shell.execute_reply": "2021-01-17T19:30:25.414449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>557</th>\n",
       "      <th>560</th>\n",
       "      <th>571</th>\n",
       "      <th>572</th>\n",
       "      <th>573</th>\n",
       "      <th>574</th>\n",
       "      <th>575</th>\n",
       "      <th>576</th>\n",
       "      <th>577</th>\n",
       "      <th>580</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>36.35</td>\n",
       "      <td>14.25</td>\n",
       "      <td>34.63</td>\n",
       "      <td>11.47</td>\n",
       "      <td>2.80</td>\n",
       "      <td>43.56</td>\n",
       "      <td>8.80</td>\n",
       "      <td>6.93</td>\n",
       "      <td>2.21</td>\n",
       "      <td>11.52</td>\n",
       "      <td>...</td>\n",
       "      <td>43.44</td>\n",
       "      <td>129.45</td>\n",
       "      <td>22.46</td>\n",
       "      <td>49.56</td>\n",
       "      <td>43.48</td>\n",
       "      <td>42.4</td>\n",
       "      <td>21.15</td>\n",
       "      <td>200.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00</th>\n",
       "      <td>41.11</td>\n",
       "      <td>13.00</td>\n",
       "      <td>33.18</td>\n",
       "      <td>11.60</td>\n",
       "      <td>2.76</td>\n",
       "      <td>43.52</td>\n",
       "      <td>8.56</td>\n",
       "      <td>6.89</td>\n",
       "      <td>2.26</td>\n",
       "      <td>11.58</td>\n",
       "      <td>...</td>\n",
       "      <td>43.44</td>\n",
       "      <td>129.44</td>\n",
       "      <td>22.32</td>\n",
       "      <td>49.56</td>\n",
       "      <td>43.79</td>\n",
       "      <td>42.4</td>\n",
       "      <td>21.12</td>\n",
       "      <td>100.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 02:00:00</th>\n",
       "      <td>40.55</td>\n",
       "      <td>9.45</td>\n",
       "      <td>32.55</td>\n",
       "      <td>11.46</td>\n",
       "      <td>2.76</td>\n",
       "      <td>43.87</td>\n",
       "      <td>8.80</td>\n",
       "      <td>7.18</td>\n",
       "      <td>2.20</td>\n",
       "      <td>11.58</td>\n",
       "      <td>...</td>\n",
       "      <td>43.44</td>\n",
       "      <td>129.45</td>\n",
       "      <td>22.35</td>\n",
       "      <td>50.04</td>\n",
       "      <td>43.67</td>\n",
       "      <td>42.0</td>\n",
       "      <td>21.66</td>\n",
       "      <td>100.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 03:00:00</th>\n",
       "      <td>41.33</td>\n",
       "      <td>9.35</td>\n",
       "      <td>32.54</td>\n",
       "      <td>11.60</td>\n",
       "      <td>2.76</td>\n",
       "      <td>44.10</td>\n",
       "      <td>8.72</td>\n",
       "      <td>6.83</td>\n",
       "      <td>2.27</td>\n",
       "      <td>11.64</td>\n",
       "      <td>...</td>\n",
       "      <td>44.04</td>\n",
       "      <td>129.45</td>\n",
       "      <td>22.40</td>\n",
       "      <td>49.32</td>\n",
       "      <td>44.34</td>\n",
       "      <td>41.6</td>\n",
       "      <td>21.25</td>\n",
       "      <td>200.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 04:00:00</th>\n",
       "      <td>40.76</td>\n",
       "      <td>9.40</td>\n",
       "      <td>32.47</td>\n",
       "      <td>11.55</td>\n",
       "      <td>4.12</td>\n",
       "      <td>43.98</td>\n",
       "      <td>8.72</td>\n",
       "      <td>6.98</td>\n",
       "      <td>2.27</td>\n",
       "      <td>11.64</td>\n",
       "      <td>...</td>\n",
       "      <td>44.40</td>\n",
       "      <td>129.44</td>\n",
       "      <td>22.40</td>\n",
       "      <td>49.68</td>\n",
       "      <td>43.55</td>\n",
       "      <td>42.0</td>\n",
       "      <td>20.99</td>\n",
       "      <td>200.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 348 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       1      2      4      5     6      7     9     10   \\\n",
       "timestamp                                                                  \n",
       "2017-01-01 00:00:00  36.35  14.25  34.63  11.47  2.80  43.56  8.80  6.93   \n",
       "2017-01-01 01:00:00  41.11  13.00  33.18  11.60  2.76  43.52  8.56  6.89   \n",
       "2017-01-01 02:00:00  40.55   9.45  32.55  11.46  2.76  43.87  8.80  7.18   \n",
       "2017-01-01 03:00:00  41.33   9.35  32.54  11.60  2.76  44.10  8.72  6.83   \n",
       "2017-01-01 04:00:00  40.76   9.40  32.47  11.55  4.12  43.98  8.72  6.98   \n",
       "\n",
       "                      11     12   ...    557     560    571    572    573  \\\n",
       "timestamp                         ...                                       \n",
       "2017-01-01 00:00:00  2.21  11.52  ...  43.44  129.45  22.46  49.56  43.48   \n",
       "2017-01-01 01:00:00  2.26  11.58  ...  43.44  129.44  22.32  49.56  43.79   \n",
       "2017-01-01 02:00:00  2.20  11.58  ...  43.44  129.45  22.35  50.04  43.67   \n",
       "2017-01-01 03:00:00  2.27  11.64  ...  44.04  129.45  22.40  49.32  44.34   \n",
       "2017-01-01 04:00:00  2.27  11.64  ...  44.40  129.44  22.40  49.68  43.55   \n",
       "\n",
       "                      574    575    576    577   580  \n",
       "timestamp                                             \n",
       "2017-01-01 00:00:00  42.4  21.15  200.0  108.0  69.0  \n",
       "2017-01-01 01:00:00  42.4  21.12  100.0  112.0  43.0  \n",
       "2017-01-01 02:00:00  42.0  21.66  100.0  112.0  42.0  \n",
       "2017-01-01 03:00:00  41.6  21.25  200.0  112.0  42.0  \n",
       "2017-01-01 04:00:00  42.0  20.99  200.0  120.0  47.0  \n",
       "\n",
       "[5 rows x 348 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.loc[:,df.isna().sum() < 100].copy()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, our data might still have missing timestamps, which is why we insert rows whose index are the missing timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T19:30:25.417448Z",
     "iopub.status.busy": "2021-01-17T19:30:25.417448Z",
     "iopub.status.idle": "2021-01-17T19:30:25.479451Z",
     "shell.execute_reply": "2021-01-17T19:30:25.478449Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx in all_dates.difference(df2.index):\n",
    "    df2.loc[idx] = pd.Series(dtype='float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one solution to the missing entries problem, we decided to interpolate the data linearly, that is, for each column (location), the missing entries are filled with values that follow a linear trend to other entries. There are other interpolation methods as well, but we decided to go with this method. This interpolation should not affect the inference much as for each column there are only at most 100 missing entries, and the dataframe has more than 25000 rows.\n",
    "\n",
    "After the interpolation step, we sum over all columns (locations) as we only wish to predict the hourly \"total\" electricity demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T19:30:25.484450Z",
     "iopub.status.busy": "2021-01-17T19:30:25.483451Z",
     "iopub.status.idle": "2021-01-17T19:30:25.824449Z",
     "shell.execute_reply": "2021-01-17T19:30:25.824449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp\n",
       "2017-01-01 00:00:00    7985.77\n",
       "2017-01-01 01:00:00    7780.45\n",
       "2017-01-01 02:00:00    7676.35\n",
       "2017-01-01 03:00:00    7722.80\n",
       "2017-01-01 04:00:00    7716.57\n",
       "Name: kWh, dtype: float64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df2.sort_index().interpolate().sum(axis=1).rename('kWh')\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step in this section, we save the aggregated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-01-17T19:30:25.827481Z",
     "iopub.status.busy": "2021-01-17T19:30:25.827481Z",
     "iopub.status.idle": "2021-01-17T19:30:25.904449Z",
     "shell.execute_reply": "2021-01-17T19:30:25.904449Z"
    }
   },
   "outputs": [],
   "source": [
    "file_name = 'hourly_total.csv'\n",
    "df3.to_csv(file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
